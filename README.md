# ğŸ¦– **RAWRÂ Agent â€“ _Read And Write Report_**  
* A starter workflow template for [NVIDIAÂ AIQÂ Toolkit](https://github.com/NVIDIA/AIQToolkit) by **JeremyÂ Kesten** (https://linktr.ee/JeremyKplatform )Â 

* Produced for and submitted to the Nvidia AgentIQ Hackathon 2025 - https://developer.nvidia.com/agentiq-hackathon


> **TL;DR** Access the Nvidia AgentIQ chat UI locally, to prompt an agent to look at an image (URL or local file) â†’ the first agent tool asks your preferred vision enabled LLM or NimOCR to extract structuredâ€¯JSON â†’ a second agent tool function converts the JSON into **ReportÂ Creator** (https://github.com/darenr/report_creator) templates â†’ instantly get a polished, singleâ€‘file HTML report.

> Recommended Viewing on Nvidia AgentIQ - https://www.youtube.com/watch?v=H65OluZaiZQ&t=153s
---

## ğŸŒŸÂ Whatâ€™s inside?

| Feature | Details |
|---------|---------|
| **Image â†’ JSON** | Uses a vision enabled LLM (default: `build.nvidia.com`, easily swappable for OpenAI, etc.) to â€œlookâ€ at an image and answer with JSON. Also includes example scripts for running a PaddleOCR NIM docker container, for more sensitive applications, where an external LLM is not possible. Resizes large images before scanning to save tokens. Extended formats for PaddleOCR NIM - can scan JPEG, PNG, GIF, TIFF, WEBP, BMP |
| **Templateâ€‘driven reports** | **ReportÂ Creator** renders the JSON into eyeâ€‘catching HTML via the templates in `report_templates/`. |
| **Oneâ€‘call flexibility** | For multiple report types, you can pick any custom pre-setup template just by passing its name in a single functionâ€‘call parameter. |
| **Batteries included** | Works as a complete [AIQ](https://github.com/NVIDIA/AIQToolkit) workflow, built to be a scaffolding so you can extend the logic between a basic example of vision llm â€œreadâ€ and report â€œwrite.â€  For instance, add an MCP extend analysis of the vision data, before writing the report. |

---

## ğŸ¦•Â Getting Started

1. **Download AIQToolkit**
   ```bash
   mkdir -p ~/<yourâ€‘AIQtoolkitâ€‘dir>
   git clone https://github.com/NVIDIA/AIQToolkit
   #  for local dev we install in WSL in ~/aiqtoolkit 
   ```

2. **Clone or fork this AgentIQ Workflow**  
   ```bash
   cd <yourâ€‘AIQtoolkitâ€‘dir>
   mkdir -p ~/<yourâ€‘AIQtoolkitâ€‘dir>/workflows
   cd workflows
   git clone https://github.com/jeremykpark/rawr_agent.git
   ```

> _Assumes you already have PythonÂ 3.9â€¯+ and `uv`â€¯or `pip` handy._

3. **Install AIQToolkit**  
   ```bash
   Create a new .venv environment and Install AIQTOOLKIT
   #  follow the official AIQToolkit setup guide :
   #  https://docs.nvidia.com/aiqtoolkit/latest/quick-start/installing.html
   
   ```

4. **Register this workflow with AIQ**  
   ```bash
   cd ~/<yourâ€‘AIQtoolkitâ€‘dir>/workflows/rawr_agent
   uv pip install -e .


5. **Launch the workflow server from the workflow root dir**  
   ```bash
    cd ~/<yourâ€‘AIQtoolkitâ€‘dir>/workflows/rawr_agent
   aiq serve --config_file configs/config.yml
   ```

6. **Launch the AIQ UI in a separate terminal**  
   ```bash
   cd ~/<yourâ€‘AIQtoolkitâ€‘dir>/external/aiqtoolkit-opensource-ui
   npm run dev

   # follow the official AIQ UI setup guide first - NPM version v18.17.0 or new required:
   # Ref: https://docs.nvidia.com/aiqtoolkit/latest/quick-start/launching-ui.html
   ```

7. **Open your browser at** <http://localhost:3000>  
   *Start chatting - test with one of the prompts in README_prompt_suggestions.md; watch the server terminals for logs/errors.*

8. **Go RAWR in the jungle**  
   *Use the chat prompt to point the agent at any image and enjoy the autoâ€‘generated reports in `report_exports/` (selfâ€‘contained interactive HTML). There are suggested prompts in README_prompt_suggestions.md to get you started.*

---

## ğŸ–¼ï¸Â Sample Flyer Included

The default setup is to read this included sample file and create a report on the data inside.

| <img src="https://github.com/jeremykpark/rawr_agent/blob/main/img/birthday-party-flyer.jpg" alt="Sample Flyer" width="20%" height="20%"> | <img src="https://github.com/jeremykpark/rawr_agent/blob/main/img/report-sample.jpg" alt="Sample Report" width="30%" height="20%"> |

---

## ğŸ§©Â Template System

Create new templates in `report_templates/`. Set them up in rawr_report_template.py to call them by name.
Generated reports are saved to /report_exports as an HTML file.

Click here to see "Kitchen Sink" an example of some of the widgets you can access for your own reports: 
[Kitchen Sink Widget Sample](https://darenr.github.io/report_creator/)

Reports are powered by **[ReportÂ Creator](https://report-creator.readthedocs.io/en/latest/api.html)** by Daren Race.  

---
## ğŸ“½ï¸ Walkthrough Video

<a href="https://www.youtube.com/watch?v=h07zOIEMiV0" target="_blank">
 <img src="https://github.com/jeremykpark/rawr_agent/blob/main/img/video-screenshot.png" alt="Walkthrough Video" width="240" height="135" border="10" />
</a>

---

## ğŸ—ï¸Â BuildÂ YourÂ Ownâ€¯RAWR

This repo is deliberately minimal and is to be used as scaffolding for your own projects. Insert your own logic between **read** (LLMÂ vision) and **write** (HTMLÂ report):

```mermaid
graph LR
  A(Image) -->|LLM Vision| B(JSON)
  B -->|Your Code ğŸ¤–| C(Enhanced JSON or extra data)
  C -->|Report Creator| D(Beautiful HTML)
```

---

## ğŸŒ‹Â Contributing / Issues

Itâ€™s a public repoâ€”PRs & issues are welcome! Letâ€™s make this starter template an **even louder RAWR**.

> â€œAh, now eventually you do plan to have dinosaurs on your, on your dinosaur tour, right? Hello?â€ â€” **Dr.Â IanÂ Malcolm**

---

## ğŸ“„Â License

Distributed under the **MIT License**.Â See `LICENSE` for more information.
